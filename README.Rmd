---
title: "How income varies across college major categories"
author: "Maurício Collaça"
date: "Nov 1st 2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The hyphotesis question

Is there an association between college major category and income?

## Requirements

    install.packages("devtools")
    devtools::install_github("jhudsl/collegeIncome")
    devtools::install_github("jhudsl/matahari")

```{r message=FALSE, warning=FALSE}
library(collegeIncome)
data(college)
library(matahari)
library(ggplot2);library(GGally);library(dplyr)
```

Custom functions
```{r}
wordwrap <- function(x, width = 10)
    lapply(strwrap(x, width = width, simplify = FALSE), paste, collapse="\n")
labelwrap <- function(x)
    gsub("_", " ", sub("perc_", "% ", x))
customtable <- function(x) 
    knitr::kable(x, col.names = labelwrap(names(x)), digits = 3)
pval <- function(x) {
    f <- summary(x)$f
    p <- pf(f[1], f[2], f[3], lower.tail = FALSE)
    attributes(p)<-NULL
    p
}
```

## Data validations

A codebook for the dataset is given below:

* rank: Rank by median earnings
* major_code: Major code
* major: Major description
* major_category: Category of major
* total: Total number of people with major
* sample_size: Sample size of full-time, year-round individuals used for income/earnings estimates: p25th, median, p75th
* p25th: 25th percentile of earnings
* median: Median earnings of full-time, year-round workers
* p75th: 75th percentile of earnings
* perc_men: % men with major (out of total)
* perc_women: % women with major (out of total)
* perc_employed: % employed (out of total)
* perc_employed_fulltime: % employed 35 hours or more (out of employed)
* perc_employed_parttime: % employed less than 35 hours (out of employed)
* perc_employed_fulltime_yearround: % employed at least 50 weeks and at least 35 hours (out of employed and full-time)
* perc_unemployed: % unemployed (out of employed)
* perc_college_jobs: % with job requiring a college degree (out of employed)
* perc_non_college_jobs: % with job not requiring a college degree (out of employed)
* perc_low_wage_jobs: % in low-wage service jobs (out of total)

### Generalized pairs plot of all numeric variables

There are some expected relatioships:

* The sample size and total number of people with major are highly positive correlated.
* The percent of woman and men are perfectly negative correlated.
* The percent of employed and unemployed are perfectly negative correlated.

There are also unexpected relationships:

* The rank is not strongly related with anything
* The percent of employed fulltime can't be correlated, suggesting that Infinite values happened.
* The percent of college jobs and non college jobs are not perfectly negative correlated which denotes miscalculations.

```{r fig.height=20, fig.width=20, message=FALSE, warning=FALSE, cache=TRUE}
college %>%
    select(everything(), -c(2:4)) %>%
    ggpairs(cardinality_threshold = 16, columnLabels = labelwrap(names(.)))
```

### Each observation is a major
```{r}
nrow(college)==length(unique(college$major))
```

### Incomplete cases
```{r}
NACols <- names(which(colSums(is.na(college)) > 0))
college %>%
    filter(!complete.cases(.)) %>%
    select(major_category, major_code, one_of(NACols)) %>%
    customtable
```

### Observations with invalid percents

A helper function to check whether the value is a wrong percent, assuming a range from 0 to 1, inclusive.
```{r}
is.wrong <- function(x, min=0, max=1)
    is.na(x) | is.infinite(x) | (is.numeric(x) & (x < min | x > max))
```

Which columns have wrong values
```{r}
columnScope <- grep("^perc_",names(college), value = TRUE)
(wrongCols <- names(which(colSums(sapply(college[, columnScope], is.wrong))>0)))
```

Which rows have wrong values
```{r}
wrongRows <- apply(sapply(wrongCols,
                          function(col) is.wrong(college[, col])),
                   1, any)
college %>%
    filter(wrongRows) %>%
    select(rank, major_category, major_code, one_of(wrongCols)) %>%
    customtable
```

Invalid values such as `NaN` (not a number), `Inf` (infinite) and `NA` (missing) foster problems and bias in calculations.  It's a best practice to get rid of them, as much as it makes sense, documenting those transformations for reproducibility purposes.

Also, percents must not be outside the range 0 to 1.

There's no raw data to recalculate the underlying percents.

As the hypothesis question is directly to the rank and not the percents, and, the ranks are perfectly uniform, it's assumed that a good strategy is not to remove incomplete observations but fix the wrong percents by their major category mean, or prefferably median, avoiding bias as and if the percents were taken as regression terms.

## Data transformations

### Category abbreviation

Abbreviate major category to fit in tiny spaces, e.g. axis labels report columns
```{r}
college <- college %>%
    mutate(category = factor(abbreviate(major_category, minlength=3)))

college %>%
    select(category, major_category) %>%
    distinct %>%
    customtable
```

### Imputing median values

As the percents are originated from median statistics and in order to minimize bias, it's assumed the median is a better imputing value than the mean.
```{r}
college <- college
for(col in seq_along(wrongCols)) {
    wrongColRows <- is.wrong(college[, wrongCols[col]])
    college[wrongColRows, wrongCols[col]] <- 
        median(college[!wrongColRows, wrongCols[col]])
}
```

Rows after imputation
```{r}
college %>%
    filter(wrongRows) %>%
    select(rank, major_category, major_code, one_of(wrongCols)) %>%
    customtable
```

## Exploratory Data Analysis

As stated in the codebook, the rank is calculated from median earnings of full-time, year-round workers, understood as the rank is the response variable and its main predictor is the median.

The following percents pairs are understood as complementary, i.e., each sum should result in 1 (100%):

    perc_men: % men with major (out of total)
    perc_women: % women with major (out of total)
    
    perc_employed: % employed (out of total)
    perc_unemployed: % unemployed (out of employed)
    
    perc_employed_fulltime: % employed 35 hours or more (out of employed)
    perc_employed_parttime: % employed less than 35 hours (out of employed)

    perc_college_jobs: % with job requiring a college degree (out of employed)
    perc_non_college_jobs: % with job not requiring a college degree (out of employed)

The following percents stand alone:

    perc_employed_fulltime_yearround: % employed at least 50 weeks and at least 35 hours (out of employed and full-time)
    perc_low_wage_jobs: % in low-wage service jobs (out of total)

These assumptions drive the following explorations.

### Generalized pairs plot of all numeric variables after imputing

After imputing data, the previoulsy expected relatioships remain:

* The sample size and total number of people with major are highly positive correlated .
* The percent of woman and men are perfectly negative correlated.
* The percent of employed and unemployed are perfectly negative correlated.

After imputing data, the previously unexpected relationships changed but still remain:

* The rank is not strongly related with any variable.
* The percent of employed fulltime now can be correlated, however, it's not perfectly negative correlated with the percent of unemployed.
* The percent of college jobs and non college jobs are not perfectly negative correlated as they weren't before.

```{r fig.height=20, fig.width=20, message=FALSE, warning=FALSE, cache=TRUE}
college %>%
    select(everything(), -c(2:4,20)) %>%
    ggpairs(cardinality_threshold = 16, columnLabels = labelwrap(names(.)))
```

### Ranking reproducibility

Although the codebook states that the rank is by median earnings, it was not possible to reproduce it with the function `rank()`.  It's found even an unexpected negative correlation between them. The analysis will continue without knowning the ranking process.

```{r}
ggplot(college, aes(x=rank, y=rank(median))) +
    geom_point(aes(color=category)) +
    geom_smooth(method="lm")
```

### Median earning distribution

Comparing the distribution kernel density and the normal curve one can see that the distribution of the median earning of each major is not normally distributed.

```{r}
x <- college$median
ggplot(college, aes(x=median), size=1) +
    geom_density(aes(color="Kernel"), fill="dark red", alpha=0.2) +
    stat_function(aes(color="Normal"), fun=dnorm, args=list(mean=mean(x), sd=sd(x))) +
    scale_color_manual("Density", values = c(Kernel="dark red", Normal="blue")) +
    geom_vline(aes(xintercept = median(x), linetype="Median")) +
    geom_vline(aes(xintercept = mean(x), linetype="Mean")) +
    scale_linetype_manual("Centrality", values = c(Median=1, Mean=2))
```

### Median earning by major category

There are potential influential points that deservers investigation.

```{r fig.height=4, fig.width=9}
ggplot(college, aes(y=median, x=category, fill=category)) +
    geom_boxplot(show.legend = FALSE)
```

The Interdisciplinary category has only one major, ranked bellow 100.  As we cannot estimate effects of a category with a single major, it will be removed.

```{r}
college <- college %>%
    filter(category != "Int")
```

```{r fig.height=4, fig.width=9}
ggplot(college, aes(y=median, x=category, fill=category)) +
    geom_violin() +
    geom_dotplot(binaxis='y', stackdir='center', fill="black",
                 dotsize=1.5, binwidth = 1000) +
    theme(legend.position = "none")
```

## Regression inference

The category t-values and their p-values that are all bigger than alpha mean not significant.

The model f-value and its p-value that is bigger than alpha mean not significant.

```{r}
fit1 <- lm(median ~ category, college)
summary(fit1)
anova(fit1)
```

### Residual analysis

In the first plot there's some kind of undesired systematic pattern and three outlying observations.

In the second plot there is some violation in the normality assumption of the residuals.

**It's not a good model.**

```{r fig.width=9, fig.height=10}
par(mfrow=c(3,2))
plot(fit1, which = 1:6, cex.id = 1, col="dark gray")
```

### Outliers

Leverage measures (hat values) can be useful for diagnosing data entry errors and points that have a high potential for influence.

Influence measures explains how removing points impact a particular aspect of the model.

#### Influence measures

```{r}
inf.measures <- influence.measures(fit1)
summary(inf.measures)
```

#### Influential observations
```{r}
influential <- unname(apply(inf.measures$is.inf, 1, any))
college %>%
    select(category, major_code, major, total, sample_size, median, rank) %>%
    filter(influential) %>% customtable()
```

#### What-if removing influential observations?

According to the model p-value, it's an even worse model.

```{r fig.width=9, fig.height=10}
college2 <- college %>% filter(!influential)
anova(lm(median ~ category, college2))
```

### Adding other terms

One can experiment adding other terms not correlated to category like gender effects and effects related to type of job (jobs requiring a college degree and jobs that are low-wage service positions).

```{r}
fit2 <- lm(median ~ category + perc_women, college)
fit3 <- lm(median ~ category + perc_college_jobs, college)
fit4 <- lm(median ~ category + perc_low_wage_jobs, college)
```
```{r}
anova(fit1, fit2)
```
```{r}
anova(fit1, fit3)
```
```{r}
anova(fit1, fit4)
```

No significant improvement in the model.
